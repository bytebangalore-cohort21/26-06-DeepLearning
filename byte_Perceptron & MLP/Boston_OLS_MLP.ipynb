{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from sklearn.datasets import load_boston # dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels.stats.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate dataset and create DataFrame \n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "target = pd.DataFrame(boston.target, columns=[\"MEDV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows,Columns: (506, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic exploratory analyses \n",
    "print(\"Rows,Columns:\",df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into training and testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, target, test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting using stats model\n",
    "model_1 = smf.OLS(Y_train,X_train).fit()\n",
    "prediction_1 = model_1.predict(X_train) # predict y_train values\n",
    "prediction_2 = model_1.predict(X_test)# predict y_test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.958</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.957</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   604.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 13 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>2.06e-226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:38:20</td>     <th>  Log-Likelihood:    </th> <td> -1063.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   354</td>      <th>  AIC:               </th> <td>   2153.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   341</td>      <th>  BIC:               </th> <td>   2204.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.0602</td> <td>    0.044</td> <td>   -1.362</td> <td> 0.174</td> <td>   -0.147</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0487</td> <td>    0.017</td> <td>    2.833</td> <td> 0.005</td> <td>    0.015</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>    0.0598</td> <td>    0.079</td> <td>    0.759</td> <td> 0.448</td> <td>   -0.095</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    3.4411</td> <td>    1.074</td> <td>    3.204</td> <td> 0.001</td> <td>    1.328</td> <td>    5.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>   -3.6557</td> <td>    4.060</td> <td>   -0.900</td> <td> 0.369</td> <td>  -11.642</td> <td>    4.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    5.5790</td> <td>    0.357</td> <td>   15.618</td> <td> 0.000</td> <td>    4.876</td> <td>    6.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>   -0.0085</td> <td>    0.017</td> <td>   -0.509</td> <td> 0.611</td> <td>   -0.042</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -0.8128</td> <td>    0.235</td> <td>   -3.465</td> <td> 0.001</td> <td>   -1.274</td> <td>   -0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.1626</td> <td>    0.085</td> <td>    1.917</td> <td> 0.056</td> <td>   -0.004</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0074</td> <td>    0.005</td> <td>   -1.476</td> <td> 0.141</td> <td>   -0.017</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.3828</td> <td>    0.133</td> <td>   -2.876</td> <td> 0.004</td> <td>   -0.645</td> <td>   -0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0174</td> <td>    0.003</td> <td>    5.420</td> <td> 0.000</td> <td>    0.011</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.4705</td> <td>    0.060</td> <td>   -7.823</td> <td> 0.000</td> <td>   -0.589</td> <td>   -0.352</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>134.338</td> <th>  Durbin-Watson:     </th> <td>   1.878</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 907.269</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.423</td>  <th>  Prob(JB):          </th> <td>9.75e-198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.308</td>  <th>  Cond. No.          </th> <td>8.72e+03</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.958\n",
       "Model:                            OLS   Adj. R-squared:                  0.957\n",
       "Method:                 Least Squares   F-statistic:                     604.3\n",
       "Date:                Fri, 13 Apr 2018   Prob (F-statistic):          2.06e-226\n",
       "Time:                        14:38:20   Log-Likelihood:                -1063.7\n",
       "No. Observations:                 354   AIC:                             2153.\n",
       "Df Residuals:                     341   BIC:                             2204.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "CRIM          -0.0602      0.044     -1.362      0.174      -0.147       0.027\n",
       "ZN             0.0487      0.017      2.833      0.005       0.015       0.082\n",
       "INDUS          0.0598      0.079      0.759      0.448      -0.095       0.215\n",
       "CHAS           3.4411      1.074      3.204      0.001       1.328       5.554\n",
       "NOX           -3.6557      4.060     -0.900      0.369     -11.642       4.330\n",
       "RM             5.5790      0.357     15.618      0.000       4.876       6.282\n",
       "AGE           -0.0085      0.017     -0.509      0.611      -0.042       0.024\n",
       "DIS           -0.8128      0.235     -3.465      0.001      -1.274      -0.351\n",
       "RAD            0.1626      0.085      1.917      0.056      -0.004       0.329\n",
       "TAX           -0.0074      0.005     -1.476      0.141      -0.017       0.002\n",
       "PTRATIO       -0.3828      0.133     -2.876      0.004      -0.645      -0.121\n",
       "B              0.0174      0.003      5.420      0.000       0.011       0.024\n",
       "LSTAT         -0.4705      0.060     -7.823      0.000      -0.589      -0.352\n",
       "==============================================================================\n",
       "Omnibus:                      134.338   Durbin-Watson:                   1.878\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              907.269\n",
       "Skew:                           1.423   Prob(JB):                    9.75e-198\n",
       "Kurtosis:                      10.308   Cond. No.                     8.72e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.72e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the Summary\n",
    "\n",
    "In the summary we see some interesting results. The INDUS coefficient (proportion of non-retail business acres per town) is not nearly statistically significant at the 5% or 10% level. The same goes for the AGE and NOX variables.\n",
    "\n",
    "There seems to be no autocorrelation (as expected as this is not a time-series problem).\n",
    "\n",
    "Overall, the Adjusted R^2 score is great, but how about RMSE (root mean square error), lets have a loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training data: 4.884014034209973\n",
      "RMSE for test data: 5.10962919003768\n"
     ]
    }
   ],
   "source": [
    "rmse_training = sqrt(mean_squared_error(Y_train, prediction_1))\n",
    "print(\"RMSE for training data:\", rmse_training)\n",
    "rmse_test = sqrt(mean_squared_error(Y_test,prediction_2))\n",
    "print(\"RMSE for test data:\", rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Scaling \n",
    "\n",
    "A neural network works best if the inputs are centered and white. That means that their covariance is diagonal and the mean is the zero vector. Why does it improve things? It is only because the optimisation of the neural net works more gracefully, since the hidden activation functions don't saturate that fast and thus do not give you near zero gradients early on in learning.\n",
    "\n",
    "\n",
    "For gradient descent, you need to choose the learning rate...but a good learning rate ( at least on 1st hidden layer) depends on the input scaling For small [ but relevant] inputs we will typically require larger weights, so you would like larger learning rate for those weight ( to get there faster), and v.v for large inputs... since you only want to use a single learning rate, you rescale your inputs. ( and whitening ie decorellating is also important for the same reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP: Hyper-parameters\n",
    "\n",
    "The first parameter, hidden_layer_sizes, is used to set the size of the hidden layers. In our script we will create three layers of 10 nodes each. There is no standard formula for choosing the number of layers and nodes for a neural network and it varies quite a bit depending on the problem at hand. The best way is to try different combinations and see what works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training data: 3.8847219541582168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(20,15,10),solver = 'sgd')  \n",
    "mlp.fit(X_train, Y_train.astype(int))\n",
    "predictions_train = mlp.predict(X_train) \n",
    "rmse_train = sqrt(mean_squared_error(Y_train, predictions_train)) \n",
    "#print(mlp)\n",
    "print(\"RMSE for training data:\", rmse_train)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(13, 14, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.228164130255489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(19, 13, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 5.083439635670582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(17, 15, 9), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 3.9326748785788275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(18, 10, 8), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.482608712016728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(13, 15, 8), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.292793004708874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(19, 14, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 3.7957389133950463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(12, 15, 7), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.24672366557708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(11, 15, 7), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 5.009348940433414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(12, 15, 8), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.500395096784996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(10, 15, 7), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 23.068680110410376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(14, 11, 8), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.625416415449752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(13, 15, 8), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.4187165423673225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(16, 13, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.425939758759382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(16, 15, 7), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.497207862011362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(12, 10, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.326095886532777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(19, 12, 7), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.231198907003024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(18, 12, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.611647875409555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(12, 14, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.6391621869180835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(12, 11, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.609379131079996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(11, 11, 9), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.747281652413822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(18, 14, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.504981969775755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(19, 10, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.290920876175363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(19, 10, 8), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.3897640356549505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(14, 15, 7), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.516714798888254\n",
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(15, 10, 8), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "RMSE for training data: 4.400180704100386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "for i in range(25):\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(random.randint(10,20),random.randint(10,15), random.randint(7,10)))  \n",
    "    mlp.fit(X_train, Y_train.astype(int))\n",
    "    predictions_train = mlp.predict(X_train) \n",
    "    rmse_train = sqrt(mean_squared_error(Y_train, predictions_train)) \n",
    "    print(mlp)\n",
    "    print(\"RMSE for training data:\", rmse_train)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training data: 3.2379487852014663\n"
     ]
    }
   ],
   "source": [
    "test_model = MLPRegressor(hidden_layer_sizes = (19, 14, 10),solver = 'sgd',alpha = 0.1)\n",
    "test_model.fit(X_train,Y_train.astype(int))\n",
    "predictions_test = test_model.predict(X_test)\n",
    "rmse_test = sqrt(mean_squared_error(Y_test, predictions_test)) \n",
    "#print(mlp)\n",
    "print(\"RMSE for training data:\", rmse_test)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "prediction_testseries = pd.Series(predictions_test)\n",
    "residuals = Y_test.values - predictions_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 152)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGnpJREFUeJzt3X9wXPV57/HPY0WkspNWEAzFC8akcdVARKxWE8w4bUnS\nWFBSvKFJDIVJmt4Lkw65jblUHfviy49gYre60zqd3M4U0jZt7RC5qRFOncYYnEw7DHYiIoEwxAmE\nYFhTUMcoCXgbL9LTP85ZsxbS2bPSnj374/2a8Wj37NnV9yRCH53vj+dr7i4AAGazIO0GAADqG0EB\nAIhEUAAAIhEUAIBIBAUAIBJBAQCIRFAAACIRFACASAQFACDSm9JuQDWcfvrpvmzZsrSbAQAN5ZFH\nHvlPd19c7rymCIply5ZpeHg47WYAQEMxs2fjnEfXEwAgEkEBAIhEUAAAIhEUAIBIBAUAIFJTzHqa\ni6GRnAb2HNKRibyWdHaov69L2Z5M2s0CgLrTkkExNJLThp1jyhcmJUm5ibw27ByTJMICAKZpya6n\ngT2HToREUb4wqYE9h1JqEQDUr5YMiiMT+RmP5ybyOm/9bq3ask9DI7katwoA6lNLBsWSzo5ZX3MF\ngbFucFTL1u/WitvvJzQAtLSWDIr+vi51tLfFOnciX1D/Pz1KWABoWS0ZFNmejDZf2a1MZ4csxvmF\nKde6wVFtHBpLvG0AUG/M3dNuw7z19vb6fIoCrtqyT7lZxi2m62hfoM1XXsjsKAANz8wecffecue1\n5B3FdJV0ReULU9qwc4yuKAAtI9WgMLO/NbOXzOzxkmOnmdleM/tB+PXUpNtR7Irq7GiPdX6+MKl1\ng6PMjgLQEtK+o/iSpEunHVsv6UF3Xy7pwfB54rI9GY3eulpb167QqQvjBUZxoR5hAaCZpT5GYWbL\nJP2Lu78rfH5I0iXu/oKZnSXpW+7eFfUZ8x2jmMnGoTFt23849vltZrr6onO0Kdtd1XYAQFLijlHU\nYwmPM939hfDxf0g6M41GFH/hf/nAYU3FyNJJ9xPBQlgAaCZpdz1F8uB2Z8Zf02Z2vZkNm9nw+Ph4\nIt9/U7ZbP9x8ubauXaFMxCK9UvcceC6RtgBAWuoxKF4Mu5wUfn1pppPc/S5373X33sWLy+4NPi/Z\nnoweWv9+bV27ouzsqMkmmG4MAKXqsetpl6RPSNoSfr0v3ea8rrh2YmDPoVnXXbSZaePQmO458Jwm\n3Rm7ANDwUh3MNrN7JF0i6XRJL0q6VdKQpB2Slkp6VtLH3P1o1OckMZhdzmyD3cvPWKQfvPTqjO+5\nduVSAgNA3WiIwWx3v3qWlz5Q04bMQfEX/vQ7h6gxim37D+uZ8Ve0/bqLa9VMAJi31KfHVkMadxSz\nWbZ+d9lzKAMCoB5QwiMlbVa+zGC+MEVFWgANg6CosqsvOifWeYUpZ0c9AA2hHmc9NbTi2MX2/Ydn\nXgBSIjeRP9FV1dnRrtuuuIDuKAB1hzuKBGzKduuZLZdr1S+dFvs9bJAEoF4RFAnaft3Funbl0tjn\nF6ZcN+0gLADUF4IiYZuy3RVVpJ10pyItgLrC9NgUxN1RL9PZof6+LsYtACSC6bF1rL+vS+1t5afR\n5ibyWjc4qmXrd6vns/dzlwEgFQRFCrI9GQ185N2xu6Mk6eVjBa0bHNXGobEEWwYAb0RQpCTbk9HI\nLatjVaQttW3/YcICQE0RFCkr7tcdd78LKQiLC275Bl1RAGqCoKgDlex3UfTq8Um6ogDUBEFRR4p3\nF5WMXWzbf5iBbgCJYnpsnRoayWnDzseUL0zFfg9lQABUgumxDS7bk9GTd1xW0cruiXxBN9IdBaDK\nCIo6tynbXVFYuIKChHRFAagWgqIBFMuALGyP93+XS1o3OKpVW/YRGADmjTGKBjM0ktNtuw5qIl+I\n/Z5T2kx/9pF3M3YB4CSMUTSpbE9Go7eurqjQ4PFJZyotgDkjKBpUcWX3tSuXqnzVqMC2/Yd13vrd\nBAaAihAUDW5Ttlt/sXZF7JXdriAwrrn74WQbBqBpEBRNoHRld1wPPX2UgW4AsRAUTSTbk6lo+1Vm\nRgGIg6BoMsXtV+OOW+Qm8izSAxCJ6bFNbOPQmLbtP1zRe9hVD2gdTI/FiYV6MdfpSQruMNizG0Ap\ngqLJZXsy+sHnLtfWCmZG5QtBCXNmRgGQCIqWUTozKu74xUNPH9Uy1l0ALY+gaDHZnoyuqWCwWwrW\nXRAYQOsiKFrQ9EV6lazsJiyA1lO3s57M7FJJn5fUJumL7r5ltnOZ9TQ/QyM5rRscjX3+ApN+76Kl\n2pTtTrBVAJLW0LOezKxN0v+XdJmk8yVdbWbnp9uq5lXpQr0ppwwI0ErqMigkvUfSU+7+Q3c/Lukr\nktak3Kamtv26i7X8jEUVveehp4/qnf/3X5lKCzS5eg2KjKTnSp4/Hx5Dgvb+70sqXneRL0yp/58e\nJSyAJlavQVGWmV1vZsNmNjw+Pp52c5pG6bqLRae0xXpPYcqpGwU0sXoNipykc0qenx0eO8Hd73L3\nXnfvXbx4cU0b1wqyPRkd/Oyl2rp2RewfEupGAc2pXoPiO5KWm9l5ZnaKpKsk7Uq5TS0p25PRn1fQ\nHVXc74INkoDmUZdB4e6vSfq0pD2SnpS0w90Pptuq1lXsjrp25dLY7ykGBgv1gMb3prQbMBt3/7qk\nr6fdDrxuU7Zbveeeptu/dlAvHyvEfl+xgi3rLoDGVLcL7irBgrt0DI3kdOPgqOL+BFHCHKgvDb3g\nDo2hWDcqLga7gcZEUGBeNmW75zR2QVgAjYOgwLwVN0iqxLb9h/X2DQx0A42AoEBVZHsy+tGWy+dU\nM4qZUUB9YzAbial0sFuStq5dwWA3UCMMZiN1lQ52S9K6wVFddOfehFoEYC4ICiSqONhdyY56L/70\nuN6+YTd1o4A6QVAgccUd9ToqKEs75cHdBWMXQPoICtREtiejJ++4rOK7i237D+t89rwAUkVQoKY2\nZbv1zJbLdeZbT4n9nmOFKd04OEpYACkhKJCKAzd/sKKwcEk330s3FJAGggKpOXDzByta1f3q8Umd\nt343GyQBNcY6CtSFjUNjJ6rMxtW+QBr4KOsugLliHQUaSrEMyMIKZkYVppgZBdQCQYG6ke3J6Ik7\nLquoDIgUzIy65u6HE2oVAIICdWf7dRfr2pVL1WbxJ9I+9PRRvZNptEAiGKNA3RsayWnd4Gjs81f9\n0mnaft3FCbYIaA6MUaBpZHsyFXVHPfT0URbpAVVEUKAhFLuj4nZGFRfpMdANzB9BgYZRXNUd9+7C\nJW3ff5g7C2CeGKNAQ9o4NKYvHzisqQp+fE9d2K5bf+cC1l0AobhjFAQFGto1dz+sh54+WtF7FrYv\n0OeuvJDAQMtjMBst4cTYRQUlaY8VplioB1SAoEDD25Tt1jObL59TCXPCAiiPoEDTKG6QlOnsiP0e\nBruB8ggKNJVsT0YPrX+/tq5dofYF5e8vXNLAnkPJNwxoYG9KuwFAEooD1Rt2PqZ8YSry3NxEXqu2\n7NORibyWdHaov6+LgW6gBLOe0PSGRnKRgWEK7ixKLTqlTXd+uJvAQFNj1hMQitqve6aQkIJNkpgZ\nBQQICrSM0sFuk5Tp7JgxJEpt239Yy9bvJjDQ0hijQEvJ9mRO6k5atWWfchP5su8r7r63KdudWNuA\nepXKHYWZfdTMDprZlJn1Tnttg5k9ZWaHzKwvjfahdfT3dcVee3HPgecSbQtQr9K6o3hc0pWS/rr0\noJmdL+kqSRdIWiLpATP7ZXefrH0T0QqyPRkNP3s01n7dk+7MjkJLSuWOwt2fdPeZJq+vkfQVd/+Z\nuz8j6SlJ76lt69Bqivt1d8TYrzs3kZeHXzfsHGOxHlpCvQ1mZySV3t8/Hx4DElU6MyqufGFSN+14\nlLBA00ssKMzsATN7fIZ/a6r0+deb2bCZDY+Pj1fjI4ETdxeLTmk7cSxqDGPSnTsLNL1UF9yZ2bck\n/bG7D4fPN0iSu28On++RdJu7Pxz1OSy4Q9LizI7KMG6BBtOoC+52SbrKzN5sZudJWi7p2ym3CVB/\nX5c62tsiz8lN5LVucFQrbr+fOww0lbSmx37YzJ6XdLGk3eGdg9z9oKQdkp6Q9A1JNzDjCfUg25PR\n5iu71RZj44uJfEHrBkd1wS3fIDDQFGJ3PZnZeyUtd/e/M7PFkt4SzkxKHV1PqJWgbtSY8oX4f79c\nu3IpC/VQl+J2PcVaR2Fmt0rqldQl6e8ktUvaJmnVfBoJNJri+MPAnkOxVnRLrOpG44vb9fRhSVdI\nelWS3P2IpLcm1SignpXueVFu3KKIDZLQyOIGxXEP+qhcksxsUXJNAhpDcdzi1IXtZc91STfteFTn\nrd+tVVv2ERpoKHGDYoeZ/bWkTjO7TtIDkr6YXLOAxpDtyWjkltWxFupNurOqGw0pVlC4+/+T9FVJ\n/6xgnOIWd//LJBsGNJJKyoBIwaputmBFo5jTgjszWyDpanffXv0mVY5ZT6gnG4fGtH3/4bJ7XRSd\nurBdt/7OBSzUQ81VZcGdmf18WPb7C2a22gKflvRDSR+rVmOBZjJ9g6Ryay9ePlZgoR7qWuQdhZnd\nJ+llSQ9L+oCkMxSUvvmMu4/WpIUxcEeBelbJ2ouO9jZtvpK9ulEbce8oygXFmLt3h4/bJL0gaam7\n/1fVWloFBAXq3dBIrqK1F9SNQi1Uq9ZTofggLKXxfL2FBNAIimsvMp0dsc7PTeR14+Aoe3WjLpQL\nineb2U/Cfz+VdGHxsZn9pBYNBJpJf1+X2hfE23zVFazqpmYU0hZZwsPd4y07BRBLsSvptl0HNZEv\nlDk78OrxSa0bHNXws0cpA4JUpLofRbUwRoFGVenYhUSRQVRPo+5HAbSU0rpR8Tqkgu4oxi5QSwQF\nUAeyPRldU8F+3fcceK78SUCVEBRAndiU7Y5VM0oK6kYBtUJQAHWkWDNqYZmaUXF22gOqhaAA6ky2\nJ6Mn7rgs8u7i6ovOOfF4aCSnVVv2UcIciSEogDpVvLtYdMrrs9RNJ896KpYHyU3kT5QwZ6Eeqi3W\nVqgA0pHtyUSW8RjYc+gNNaRcwY56veeeRgkQVAV3FEADOzLL+guXtG5wlK4oVAVBATSwJWVqR+Um\n8pQwx7wRFEAD6+/rirVQbyJfYPtVzBlBATSw4kK9OGHB9quYK4ICaHClO+qVM9uYBhCFoACaQGnN\nqI722Ys+lxvTAGbC9FigiRSnw97+tYN6+djJZcw72tvU39eVRrPQ4LijAJpMtiejkVtWa2vYHWUK\ntlZlL27MFXcUQJMqt1gPiIugACDp9U2UjkzktaSzQ/19XQQNJBEUAPR6zahiOZDcRF4bdgb1oggL\nMEYBYMaaUay7QFEqQWFmA2b2PTN7zMzuNbPOktc2mNlTZnbIzPrSaB/QamZbX8G6C0jp3VHslfQu\nd79Q0vclbZAkMztf0lWSLpB0qaS/MrPZJ4UDqIrZ1lew7gJSSkHh7ve7+2vh0/2Szg4fr5H0FXf/\nmbs/I+kpSe9Jo41AK+nv63rDQj3WXaCoHsYo/kDSv4aPM5JKd41/Pjz2BmZ2vZkNm9nw+Ph4wk0E\nmlu2J6PNV3az7gIzSmzWk5k9IOkXZ3jpZne/LzznZkmvSdpe6ee7+12S7pKk3t5edpoH5ol1F5hN\nYkHh7r8V9bqZ/b6kD0n6gLsXf9HnJJ1TctrZ4TEAQErSmvV0qaQ/kXSFux8reWmXpKvM7M1mdp6k\n5ZK+nUYbAQCBtBbcfUHSmyXtNTNJ2u/un3L3g2a2Q9ITCrqkbnD3yYjPAQAkLJWgcPd3RLx2p6Q7\na9gcAECEepj1BACoYwQFACASQQEAiET1WACJo4R5YyMoACSKEuaNj64nAImarYT5usFRLVu/Wytu\nv19DI6yrrWcEBYBElStVPpEvaN3gqDYOjdWoRagUQQEgUXFLlW/ff5g7izpFUABI1EwlzGfiEjvq\n1SkGswEkqjhgPbDnkHJluqHYUa8+ERQAElcsYT40klP/Vx9VYXLmnQGWdHYwlbYOERQAaqb4C//m\ne8f06vGTZ0J1tLfpfb+ymKm0dYgxCgA1le3J6OBnL9XWtSvesKPeN783PutU2lVb9jHYnRLuKACk\nYqYd9W4cHJ31fO4u0sMdBYC6UW4qbb4wycyoFBAUAOpGnKm0zIyqPbqeANSNOFNp4y7gQ/UQFADq\nSulU2tIZUFIwM6q/r0sSFWlriaAAUJdK7y6mhwEVaWuLoABQt2aaGSXNXpF2YM8hgiIBDGYDaDiz\nDWgz0J0MggJAw5ltQJuB7mQQFAAazkzTaEsHulFdjFEAaDhRA92oPoICQEOabaAb1UdQAGgZrL2Y\nG4ICQEtg7cXcMZgNoCVErb1ANIICQEtg7cXcERQAWgJrL+aOoADQElh7MXepBIWZ3WFmj5nZqJnd\nb2ZLwuNmZn9pZk+Fr/9qGu0D0HyyPRltvrL7DduvMpBdnrl77b+p2c+7+0/Cx38k6Xx3/5SZ/bak\n/yXptyVdJOnz7n5Ruc/r7e314eHhRNsMAM3GzB5x995y56VyR1EMidAiScW0WiPpHzywX1KnmZ1V\n8wYCAE5IbR2Fmd0p6eOSfizpfeHhjKTnSk57Pjz2Qm1bBwAoSuyOwsweMLPHZ/i3RpLc/WZ3P0fS\ndkmfnsPnX29mw2Y2PD4+Xu3mAwBCid1RuPtvxTx1u6SvS7pVUk7SOSWvnR0em+nz75J0lxSMUcy9\npQCAKGnNelpe8nSNpO+Fj3dJ+ng4+2mlpB+7O91OAJCitMYotphZl6QpSc9K+lR4/OsKZjw9JemY\npE+m0zwAQFEqQeHuvzvLcZd0Q42bAwCIwMpsAEAkggIAEImgAABEIigAAJEICgBAJIICABCJoAAA\nRCIoAACRCAoAQCSCAgAQiaAAAEQiKAAAkQgKAEAkggIAEImgAABEIigAAJEICgBAJIICABAprT2z\nAQDzMDSS08CeQzoykdeSzg7193Up25NJ5HsRFADQYIZGctqwc0z5wqQkKTeR14adY5KUSFjQ9QQA\nDWZgz6ETIVGUL0xqYM+hRL4fQQEADebIRL6i4/NFUABAg1nS2VHR8fkiKACgwfT3damjve2kYx3t\nberv60rk+zGYDQANpjhgzawnAMCssj2ZxIJhOrqeAACRCAoAQCSCAgAQiaAAAEQiKAAAkczd027D\nvJnZuKRn026HpNMl/WfajUhJq157q1631LrX3kzXfa67Ly53UlMERb0ws2F37027HWlo1Wtv1euW\nWvfaW/G66XoCAEQiKAAAkQiK6ror7QakqFWvvVWvW2rda2+562aMAgAQiTsKAEAkgmKOzOxvzewl\nM3u85NhpZrbXzH4Qfj01zTYmwczOMbNvmtkTZnbQzD4THm+Fa/85M/u2mT0aXvvt4fHzzOyAmT1l\nZoNmdkrabU2CmbWZ2YiZ/Uv4vFWu+0dmNmZmo2Y2HB5r+p/3UgTF3H1J0qXTjq2X9KC7L5f0YPi8\n2bwm6SZ3P1/SSkk3mNn5ao1r/5mk97v7uyWtkHSpma2U9KeS/sLd3yHpZUn/I8U2Jukzkp4sed4q\n1y1J73P3FSXTYlvh5/0EgmKO3P3fJB2ddniNpL8PH/+9pGxNG1UD7v6Cu383fPxTBb84MmqNa3d3\nfyV82h7+c0nvl/TV8HhTXruZnS3pcklfDJ+bWuC6IzT9z3spgqK6znT3F8LH/yHpzDQbkzQzWyap\nR9IBtci1h90vo5JekrRX0tOSJtz9tfCU5xUEZ7PZKulPJE2Fz9+m1rhuKfhj4H4ze8TMrg+PtcTP\nexEbFyXE3d3MmnZKmZm9RdI/S1rn7j8J/sAMNPO1u/ukpBVm1inpXkm/knKTEmdmH5L0krs/YmaX\npN2eFLzX3XNmdoakvWb2vdIXm/nnvYg7iup60czOkqTw60sptycRZtauICS2u/vO8HBLXHuRu09I\n+qakiyV1mlnxj66zJeVSa1gyVkm6wsx+JOkrCrqcPq/mv25Jkrvnwq8vKfjj4D1qsZ93gqK6dkn6\nRPj4E5LuS7EtiQj7pv9G0pPu/uclL7XCtS8O7yRkZh2SPqhgjOabkj4SntZ01+7uG9z9bHdfJukq\nSfvc/Ro1+XVLkpktMrO3Fh9LWi3pcbXAz3spFtzNkZndI+kSBZUkX5R0q6QhSTskLVVQzfZj7j59\nwLuhmdl7Jf27pDG93l/9fxSMUzT7tV+oYOCyTcEfWTvc/bNm9nYFf2mfJmlE0rXu/rP0WpqcsOvp\nj939Q61w3eE13hs+fZOkL7v7nWb2NjX5z3spggIAEImuJwBAJIICABCJoAAARCIoAACRCAoAQCSC\nApBkZpNhddDHzexrxfUSc/icL4ZFEqcf/30z+8I82vdK+bOAZBAUQCAfVgd9l4JijzfM5UPc/X+6\n+xPVbRqQLoICeKOHVVLgzsz6zew7ZvZYyR4Ui8xsd7g3xeNmtjY8/i0z6w0ff9LMvm9m31ZQBqP4\neV8ys4+UPH8l/PoWM3vQzL4b7n+wZnrDzOwsM/u3krufX0/qfwSgiKKAQAkza5P0AQVlSmRmqyUt\nV1DfxyTtMrPfkLRY0hF3vzw87xemfc5Zkm6X9GuSfqyg3MVImW//X5I+HBZZPF3SfjPb5Seviv09\nSXvC1cFtkhbO64KBGLijAAIdYfnwYsnoveHx1eG/EUnfVVAtdrmCEiYfNLM/NbNfd/cfT/u8iyR9\ny93H3f24pMEYbTBJnzOzxyQ9oOCuZnr56u9I+qSZ3SapO9wTBEgUQQEE8u6+QtK5Cn5hF8coTNLm\ncPxihbu/w93/xt2/L+lXFQTGJjO7pYLv9ZrC//bMbIGk4hai1yi4U/m1sC0vSvq50jeGG2b9hoJK\nrV8ys4/P4VqBihAUQAl3PybpjyTdFJbQ3iPpD8L9N2RmGTM7w8yWSDrm7tskDSgIjVIHJP2mmb0t\nLMv+0ZLXfqSgS0qSrlCwU54k/YKCfR8KZvY+BaF1EjM7V9KL7n63gt3mpn9foOoYowCmcfeRsPvn\nanf/RzN7p6SHw82ZXpF0raR3SBowsylJBUl/OO0zXgi7hx6WNCFptOTluyXdZ2aPSvqGpFfD49sl\nfc3MxiQNSzppg5zQJZL6zawQtoU7CiSO6rEAgEh0PQEAIhEUAIBIBAUAIBJBAQCIRFAAACIRFACA\nSAQFACASQQEAiPTf1pZ/HeZD/ygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11736b518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(y = residuals[0], x=predictions_test)\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Re\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
